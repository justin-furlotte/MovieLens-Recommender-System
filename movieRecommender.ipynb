{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5626e50c",
   "metadata": {},
   "source": [
    "A simple movie recommendation systems using the [MovieLens dataset](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data). The original source of the data is [here](https://grouplens.org/datasets/movielens/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba634487",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc1a68d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f43805",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794edb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742\n",
       "2  22       377       1       878887116\n",
       "3  244      51        2       880606923\n",
       "4  166      346       1       886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=r_cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd52d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5b283",
   "metadata": {},
   "source": [
    "### 2.1 Terminology\n",
    "\n",
    "**Constants**:\n",
    "\n",
    " - $N$: the number of users, indexed by $n$\n",
    " - $M$: the number of movies, indexed by $m$\n",
    " - $\\mathcal{R}$: the set of indices $(n,m)$ where we have ratings in the utility matrix $Y$\n",
    "    - Thus $|\\mathcal{R}|$ is the total number of ratings\n",
    " \n",
    "**The data**:\n",
    "\n",
    " - $Y$: the utility matrix containing ratings, contains a lot of missing entries\n",
    " - `train_mat` and `valid_mat`: Utility matrices for train and validation sets, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232ebbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "N = ratings.shape[0]\n",
    "M = len(np.unique(np.array(ratings[[\"movie_id\"]])))\n",
    "\n",
    "print(N)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea06406",
   "metadata": {},
   "source": [
    "**Note**: The fraction of non-missing ratings in $Y$ is $\\frac{|\\mathcal{R}|}{NM}$, where $NM$ is the total number of entries $|Y|$ in the utility matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82e787",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8408c",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "Using a `random_state` so that results are consistent between users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f236c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed70cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings.copy()\n",
    "X_train, X_valid = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f4e84",
   "metadata": {},
   "source": [
    "### Utility matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8521bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1050971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per lecture notes\n",
    "def Construct_Y(data, N, M):\n",
    "    Y = np.zeros((N,M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n,m] = val[\"rating\"]\n",
    "        \n",
    "    return Y\n",
    "\n",
    "train_mat = Construct_Y(X_train, N, M)\n",
    "valid_mat = Construct_Y(X_valid, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaa276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c0f2d",
   "metadata": {},
   "source": [
    "The train and validation matrices have the same size, but they are created from the train and validation sets. In other words, for the validation matrix, 20% of the rows (the ones coming from the validation sets) will potentially have non-zero entries for the features, but all the other rows will have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064a666",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c29dd0",
   "metadata": {},
   "source": [
    "### Evaluation and baseline\n",
    "\n",
    "The `error` function returns RMSE. The `evaluate` function prints the train and validation RMSEs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36958912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2bdb6",
   "metadata": {},
   "source": [
    "**Note:** When we evaluate recommender systems, we are calculating train error and validation error (in this case, using the matric RMSE). First, we take then train_mat and apply our model to it. Then to calculate train error, we compare the model's prediction to the train_mat portion of the ratings. For validation error, we compare our model's predicted rating to the valid_mat portion of the ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c820de",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7820da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Global_Baseline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.N = None\n",
    "        self.M = None\n",
    "        self.means = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        N, M = X.shape\n",
    "        pred = np.zeros((N,M))\n",
    "        for j in range(M):\n",
    "            column_mean = np.nanmean(X[:,j])\n",
    "            pred[:,j] = [column_mean for inp in range(N)]\n",
    "        self.means = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c0b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qp/hky_8qn94bb4xlp8wx5fclrm0000gn/T/ipykernel_57426/3881244217.py:12: RuntimeWarning: Mean of empty slice\n",
      "  column_mean = np.nanmean(X[:,j])\n"
     ]
    }
   ],
   "source": [
    "gb = Global_Baseline()\n",
    "gb.fit(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f15ac0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.00\n",
      "Global average valid RMSE: 1.02\n"
     ]
    }
   ],
   "source": [
    "pred_Y = gb.means\n",
    "evaluate(pred_Y, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d84718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.86533</td>\n",
       "      <td>3.203883</td>\n",
       "      <td>3.101449</td>\n",
       "      <td>3.549133</td>\n",
       "      <td>3.246377</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>3.811912</td>\n",
       "      <td>3.936047</td>\n",
       "      <td>3.90795</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.86533</td>\n",
       "      <td>3.203883</td>\n",
       "      <td>3.101449</td>\n",
       "      <td>3.549133</td>\n",
       "      <td>3.246377</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>3.811912</td>\n",
       "      <td>3.936047</td>\n",
       "      <td>3.90795</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86533</td>\n",
       "      <td>3.203883</td>\n",
       "      <td>3.101449</td>\n",
       "      <td>3.549133</td>\n",
       "      <td>3.246377</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>3.811912</td>\n",
       "      <td>3.936047</td>\n",
       "      <td>3.90795</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.86533</td>\n",
       "      <td>3.203883</td>\n",
       "      <td>3.101449</td>\n",
       "      <td>3.549133</td>\n",
       "      <td>3.246377</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>3.811912</td>\n",
       "      <td>3.936047</td>\n",
       "      <td>3.90795</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.86533</td>\n",
       "      <td>3.203883</td>\n",
       "      <td>3.101449</td>\n",
       "      <td>3.549133</td>\n",
       "      <td>3.246377</td>\n",
       "      <td>3.647059</td>\n",
       "      <td>3.811912</td>\n",
       "      <td>3.936047</td>\n",
       "      <td>3.90795</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6  \\\n",
       "0  3.86533  3.203883  3.101449  3.549133  3.246377  3.647059  3.811912   \n",
       "1  3.86533  3.203883  3.101449  3.549133  3.246377  3.647059  3.811912   \n",
       "2  3.86533  3.203883  3.101449  3.549133  3.246377  3.647059  3.811912   \n",
       "3  3.86533  3.203883  3.101449  3.549133  3.246377  3.647059  3.811912   \n",
       "4  3.86533  3.203883  3.101449  3.549133  3.246377  3.647059  3.811912   \n",
       "\n",
       "          7        8         9  ...  1672  1673  1674  1675  1676  1677  1678  \\\n",
       "0  3.936047  3.90795  3.891892  ...  3.0  NaN   NaN    2.0  NaN    1.0   3.0    \n",
       "1  3.936047  3.90795  3.891892  ...  3.0  NaN   NaN    2.0  NaN    1.0   3.0    \n",
       "2  3.936047  3.90795  3.891892  ...  3.0  NaN   NaN    2.0  NaN    1.0   3.0    \n",
       "3  3.936047  3.90795  3.891892  ...  3.0  NaN   NaN    2.0  NaN    1.0   3.0    \n",
       "4  3.936047  3.90795  3.891892  ...  3.0  NaN   NaN    2.0  NaN    1.0   3.0    \n",
       "\n",
       "   1679  1680  1681  \n",
       "0  2.0   3.0  NaN    \n",
       "1  2.0   3.0  NaN    \n",
       "2  2.0   3.0  NaN    \n",
       "3  2.0   3.0  NaN    \n",
       "4  2.0   3.0  NaN    \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_Y).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4d58f",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e68a4",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "Using the [`surprise`](https://surprise.readthedocs.io/en/stable/) package which has an implementation of the SVD algorithm for collaborative filtering. You can install it as follows:\n",
    "\n",
    "```\n",
    ">> conda install -c conda-forge scikit-surprise\n",
    "or \n",
    ">> pip install scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aad220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "407bfd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0  196      242       3       881250949\n",
       "1  186      302       3       891717742"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b3c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9392083167432567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings.drop(\"timestamp\", axis=1), reader)\n",
    "\n",
    "train, valid = surprise.model_selection.train_test_split(data, test_size = 0.2)\n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors = k)\n",
    "algo.fit(train)\n",
    "svd_pred = algo.test(valid)\n",
    "accuracy.rmse(svd_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6433e",
   "metadata": {},
   "source": [
    "**Remark:** The RMSE has improved compared to the global baseline, which was 1.02 for validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
